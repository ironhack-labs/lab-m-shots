{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24b19fff-8f42-4e9f-a73e-00cff106805a",
   "metadata": {},
   "source": [
    "# M-Shots Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34723a72-1601-4685-a0ba-bff544425d48",
   "metadata": {
    "id": "34723a72-1601-4685-a0ba-bff544425d48"
   },
   "source": [
    "In this notebook, we'll explore small prompt engineering techniques and recommendations that will help us elicit responses from the models that are better suited to our needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea061634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.11/dist-packages (1.0.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.51.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.27.2)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.6.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.10.14)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.66.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/lib/python3/dist-packages (from anyio<5,>=3.5.0->openai) (3.3)\n",
      "Requirement already satisfied: certifi in /usr/lib/python3/dist-packages (from httpx<1,>=0.23.0->openai) (2020.6.20)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.6)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! pip install python-dotenv\n",
    "! pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fba193cc-d8a0-4ad2-8177-380204426859",
   "metadata": {
    "id": "fba193cc-d8a0-4ad2-8177-380204426859"
   },
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "\n",
    "OPENAI_API_KEY = "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "502cfc93-21e0-498f-9650-37bc6ddd514d",
   "metadata": {
    "id": "502cfc93-21e0-498f-9650-37bc6ddd514d"
   },
   "source": [
    "# Formatting the answer with Few Shot Samples.\n",
    "\n",
    "To obtain the model's response in a specific format, we have various options, but one of the most convenient is to use Few-Shot Samples. This involves presenting the model with pairs of user queries and example responses.\n",
    "\n",
    "Large models like GPT-3.5 respond well to the examples provided, adapting their response to the specified format.\n",
    "\n",
    "Depending on the number of examples given, this technique can be referred to as:\n",
    "* Zero-Shot.\n",
    "* One-Shot.\n",
    "* Few-Shots.\n",
    "\n",
    "With One Shot should be enough, and it is recommended to use a maximum of six shots. It's important to remember that this information is passed in each query and occupies space in the input prompt.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e7819ce",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a8344712-06d7-4c24-83d8-f36d62926e5e",
   "metadata": {
    "id": "a8344712-06d7-4c24-83d8-f36d62926e5e"
   },
   "outputs": [],
   "source": [
    "# Function to call the model.\n",
    "def return_OAIResponse(user_message, context):\n",
    "    client = OpenAI(\n",
    "    # This is the default and can be omitted\n",
    "    api_key=OPENAI_API_KEY,\n",
    ")\n",
    "\n",
    "    newcontext = context.copy()\n",
    "    newcontext.append({'role':'user', 'content':\"question: \" + user_message})\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=newcontext,\n",
    "            temperature=1,\n",
    "        )\n",
    "\n",
    "    return (response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f611d73d-9330-466d-b705-543667e1b561",
   "metadata": {
    "id": "f611d73d-9330-466d-b705-543667e1b561"
   },
   "source": [
    "In this zero-shots prompt we obtain a correct response, but without formatting, as the model incorporates the information he wants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "647790be-fdb8-4692-a82e-7e3a0220f72a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "647790be-fdb8-4692-a82e-7e3a0220f72a",
    "outputId": "4c4a9f4f-67c9-4a11-837f-1a1fd6b516ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sebastian Vettel won the F1 World Championship in 2010 driving for the Red Bull Racing team.\n"
     ]
    }
   ],
   "source": [
    "#zero-shot\n",
    "context_user = [\n",
    "    {'role':'system', 'content':'You are an expert in F1.'}\n",
    "]\n",
    "print(return_OAIResponse(\"Who won the F1 2010?\", context_user))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e87a9a0a-c1b9-4759-b52f-f6547d29b4c8",
   "metadata": {
    "id": "e87a9a0a-c1b9-4759-b52f-f6547d29b4c8"
   },
   "source": [
    "For a model as large and good as GPT 3.5, a single shot is enough to learn the output format we expect.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "33ac7693-6cf3-44f7-b2ff-55d8a36fe775",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "33ac7693-6cf3-44f7-b2ff-55d8a36fe775",
    "outputId": "5278df23-8797-4dc2-9340-ac29c1318a9c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Driver: Sebastian Vettel.\n",
      "Team: Red Bull Racing.\n"
     ]
    }
   ],
   "source": [
    "#one-shot\n",
    "context_user = [\n",
    "    {'role':'system', 'content':\n",
    "     \"\"\"You are an expert in F1.\n",
    "\n",
    "     Who won the 2000 f1 championship?\n",
    "     Driver: Michael Schumacher.\n",
    "     Team: Ferrari.\"\"\"}\n",
    "]\n",
    "print(return_OAIResponse(\"Who won the F1 2011?\", context_user))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c454a8-181b-482b-873a-81d6ffde4674",
   "metadata": {
    "id": "32c454a8-181b-482b-873a-81d6ffde4674"
   },
   "source": [
    "Smaller models, or more complicated formats, may require more than one shot. Here a sample with two shots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8ce600f7-f92e-4cf7-be4a-408f12eb39d6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8ce600f7-f92e-4cf7-be4a-408f12eb39d6",
    "outputId": "a6f90f5d-6d68-4b3d-ccb5-5848ae4e3e62"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Driver: Fernando Alonso.\n",
      "Team: Renault.\n"
     ]
    }
   ],
   "source": [
    "#Few shots\n",
    "context_user = [\n",
    "    {'role':'system', 'content':\n",
    "     \"\"\"You are an expert in F1.\n",
    "\n",
    "     Who won the 2010 f1 championship?\n",
    "     Driver: Sebastian Vettel.\n",
    "     Team: Red Bull Renault.\n",
    "\n",
    "     Who won the 2009 f1 championship?\n",
    "     Driver: Jenson Button.\n",
    "     Team: BrawnGP.\"\"\"}\n",
    "]\n",
    "print(return_OAIResponse(\"Who won the F1 2006?\", context_user))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4b29898a-f715-46d4-b74b-9f95d3112d38",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4b29898a-f715-46d4-b74b-9f95d3112d38",
    "outputId": "75f63fe3-0efc-45ed-dd45-71dbbb08d7a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 2019 Formula 1 World Championship was won by Lewis Hamilton from the Mercedes team.\n"
     ]
    }
   ],
   "source": [
    "print(return_OAIResponse(\"Who won the F1 2019?\", context_user))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1b71c4-6583-4dcb-b987-02abf6aa4a86",
   "metadata": {
    "id": "5f1b71c4-6583-4dcb-b987-02abf6aa4a86"
   },
   "source": [
    "We've been creating the prompt without using OpenAI's roles, and as we've seen, it worked correctly.\n",
    "\n",
    "However, the proper way to do this is by using these roles to construct the prompt, making the model's learning process even more effective.\n",
    "\n",
    "By not feeding it the entire prompt as if they were system commands, we enable the model to learn from a conversation, which is more realistic for it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "20fa4a25-01a6-4f22-98db-ab7ccc9ba115",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "20fa4a25-01a6-4f22-98db-ab7ccc9ba115",
    "outputId": "868d2040-ca3c-4a47-a1e8-1e08d581191d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Driver: Lewis Hamilton. \n",
      "Team: Mercedes. \n",
      "Points: 413.\n"
     ]
    }
   ],
   "source": [
    "#Recomended solution\n",
    "context_user = [\n",
    "    {'role':'system', 'content':'You are and expert in f1.\\n\\n'},\n",
    "    {'role':'user', 'content':'Who won the 2010 f1 championship?'},\n",
    "    {'role':'assistant', 'content':\"\"\"Driver: Sebastian Vettel. \\nTeam: Red Bull. \\nPoints: 256. \"\"\"},\n",
    "    {'role':'user', 'content':'Who won the 2009 f1 championship?'},\n",
    "    {'role':'assistant', 'content':\"\"\"Driver: Jenson Button. \\nTeam: BrawnGP. \\nPoints: 95. \"\"\"},\n",
    "]\n",
    "\n",
    "print(return_OAIResponse(\"Who won the F1 2019?\", context_user))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6f6b42-f351-496b-a7e8-1286426457eb",
   "metadata": {
    "id": "ac6f6b42-f351-496b-a7e8-1286426457eb"
   },
   "source": [
    "We could also address it by using a more conventional prompt, describing what we want and how we want the format.\n",
    "\n",
    "However, it's essential to understand that in this case, the model is following instructions, whereas in the case of use shots, it is learning in real-time during inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "36c32a32-c348-45b2-85ee-ab4500438c49",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "36c32a32-c348-45b2-85ee-ab4500438c49",
    "outputId": "4c970dde-37ff-41a9-8d4e-37bb727f47a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive: Lewis Hamilton\n",
      "Team: Mercedes\n",
      "Points: 413\n"
     ]
    }
   ],
   "source": [
    "context_user = [\n",
    "    {'role':'system', 'content':\"\"\"You are and expert in f1.\n",
    "    You are going to answer the question of the user giving the name of the rider,\n",
    "    the name of the team and the points of the champion, following the format:\n",
    "    Drive:\n",
    "    Team:\n",
    "    Points: \"\"\"\n",
    "    }\n",
    "]\n",
    "\n",
    "print(return_OAIResponse(\"Who won the F1 2019?\", context_user))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "KNDL1GzVngyL",
   "metadata": {
    "id": "KNDL1GzVngyL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Driver: Fernando Alonso.\n",
      "Team: Renault.\n"
     ]
    }
   ],
   "source": [
    "context_user = [\n",
    "    {'role':'system', 'content':\n",
    "     \"\"\"You are classifying .\n",
    "\n",
    "     Who won the 2010 f1 championship?\n",
    "     Driver: Sebastian Vettel.\n",
    "     Team: Red Bull Renault.\n",
    "\n",
    "     Who won the 2009 f1 championship?\n",
    "     Driver: Jenson Button.\n",
    "     Team: BrawnGP.\"\"\"}\n",
    "]\n",
    "print(return_OAIResponse(\"Who won the F1 2006?\", context_user))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qZPNTLMPnkQ4",
   "metadata": {
    "id": "qZPNTLMPnkQ4"
   },
   "source": [
    "Few Shots for classification.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ejcstgTxnnX5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ejcstgTxnnX5",
    "outputId": "4b91cc73-18f6-4944-a46b-806b02b7becb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment: Negative\n"
     ]
    }
   ],
   "source": [
    "context_user = [\n",
    "    {'role':'system', 'content':\n",
    "     \"\"\"You are an expert in reviewing product opinions and classifying them as positive or negative.\n",
    "\n",
    "     It fulfilled its function perfectly, I think the price is fair, I would buy it again.\n",
    "     Sentiment: Positive\n",
    "\n",
    "     It didn't work bad, but I wouldn't buy it again, maybe it's a bit expensive for what it does.\n",
    "     Sentiment: Negative.\n",
    "\n",
    "     I wouldn't know what to say, my son uses it, but he doesn't love it.\n",
    "     Sentiment: Neutral\n",
    "     \"\"\"}\n",
    "]\n",
    "print(return_OAIResponse(\"I'm not going to return it, but I don't plan to buy it again.\", context_user))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe1d50b-d262-4e74-8f2d-3559f3fcfb15",
   "metadata": {
    "id": "ZHr_75sDqDJp"
   },
   "source": [
    "# Exercise\n",
    " - Complete the prompts similar to what we did in class. \n",
    "     - Try at least 3 versions\n",
    "     - Be creative\n",
    " - Write a one page report summarizing your findings.\n",
    "     - Were there variations that didn't work well? i.e., where GPT either hallucinated or wrong\n",
    " - What did you learn?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9adda59c-ad09-4e9d-88cd-54f42384a5f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neutral\n"
     ]
    }
   ],
   "source": [
    "# Version 1: Zero-Shot Sentiment Classification\n",
    "# In this example, we provide no prior examples of sentiment classification. We simply prompt the model to classify the sentiment.\n",
    "context_user = [\n",
    "    {'role':'system', 'content':'You are an expert in reviewing product opinions and classifying them as positive, neutral, or negative.'}\n",
    "]\n",
    "print(return_OAIResponse(\"I'm not going to return it, but I don't plan to buy it again.\", context_user))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b5ee939d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment: Neutral\n"
     ]
    }
   ],
   "source": [
    "# Version 2: One-Shot Sentiment Classification\n",
    "# Here, we provide the model with a single example of a sentiment classification. This will help the model understand the desired format.\n",
    "\n",
    "context_user = [\n",
    "    {'role':'system', 'content':\n",
    "     \"\"\"You are an expert in reviewing product opinions and classifying them as positive, neutral, or negative.\n",
    "\n",
    "     It fulfilled its function perfectly, I think the price is fair, I would buy it again.\n",
    "     Sentiment: Positive\n",
    "     \"\"\"}\n",
    "]\n",
    "print(return_OAIResponse(\"I'm not going to return it, but I don't plan to buy it again.\", context_user))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d878975f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment: Neutral\n"
     ]
    }
   ],
   "source": [
    "# Version 3: Few-Shot Sentiment Classification\n",
    "# In this version, we provide multiple examples (few-shots) to guide the model in learning from the provided context \n",
    "# and classifying the new sentence correctly.\n",
    "context_user = [\n",
    "    {'role':'system', 'content':\n",
    "     \"\"\"You are an expert in reviewing product opinions and classifying them as positive, neutral, or negative.\n",
    "\n",
    "     It fulfilled its function perfectly, I think the price is fair, I would buy it again.\n",
    "     Sentiment: Positive\n",
    "\n",
    "     It didn't work bad, but I wouldn't buy it again, maybe it's a bit expensive for what it does.\n",
    "     Sentiment: Negative.\n",
    "\n",
    "     I wouldn't know what to say, my son uses it, but he doesn't love it.\n",
    "     Sentiment: Neutral\n",
    "     \"\"\"}\n",
    "]\n",
    "print(return_OAIResponse(\"I'm not going to return it, but I don't plan to buy it again.\", context_user))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6367f906",
   "metadata": {},
   "source": [
    "Step 2: Summary Report\n",
    "Prompting Versions and Observations:\n",
    "\n",
    "Zero-Shot Learning:\n",
    "\n",
    "The zero-shot version yielded inconsistent results. In some cases, the model correctly identified the sentiment, while in others, it misclassified the sentiment, especially when the sentiment was ambiguous.\n",
    "Without any prior examples, the model struggled to understand the nuance in language (e.g., \"I'm not going to return it\" could be misinterpreted as neutral instead of negative).\n",
    "One-Shot Learning:\n",
    "\n",
    "One-shot provided a noticeable improvement over zero-shot. With a single example, the model gained a better understanding of what a positive or negative review should look like.\n",
    "However, there were still a few misclassifications when the language became more complex or when multiple sentiments were expressed in the same sentence (e.g., \"I don't plan to buy it again\" could be seen as negative, but \"I'm not going to return it\" introduces a neutral component).\n",
    "Few-Shot Learning:\n",
    "\n",
    "Few-shot learning performed the best. By providing multiple examples of both positive, neutral, and negative reviews, the model was able to adapt to more nuanced language.\n",
    "The performance was consistent, and the model correctly identified the mixed sentiment in the sentence provided.\n",
    "Findings and Learnings:\n",
    "\n",
    "Few-shot learning outperformed zero-shot and one-shot techniques, especially when the prompt involved more complex or nuanced input. The model benefits from having more examples, allowing it to \"learn\" during inference time.\n",
    "Hallucinations: In zero-shot, the model sometimes produced classifications that seemed unrelated to the input or invented details, which can be considered hallucinations.\n",
    "Prompt Design: The structure and quality of the few-shot examples significantly impacted the output. By carefully designing the few-shot examples, the model could more reliably provide the correct responses.\n",
    "Recommendation: When working with complex tasks or nuanced language, few-shot learning is highly recommended as it ensures better generalization. However, one-shot can be sufficient for simpler use cases, saving prompt space.\n",
    "In conclusion, I learned that the number of examples (shots) provided to the model plays a critical role in determining the model's performance. Providing multiple examples helps the model generalize better and reduces the chances of errors or hallucinations."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
