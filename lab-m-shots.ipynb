{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24b19fff-8f42-4e9f-a73e-00cff106805a",
   "metadata": {},
   "source": [
    "# M-Shots Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34723a72-1601-4685-a0ba-bff544425d48",
   "metadata": {
    "id": "34723a72-1601-4685-a0ba-bff544425d48"
   },
   "source": [
    "In this notebook, we'll explore small prompt engineering techniques and recommendations that will help us elicit responses from the models that are better suited to our needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7af64239",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Skipping dataclasses as it is not installed.\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall dataclasses\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b864b15e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in c:\\users\\mends\\onedrive\\desktop\\ironhack\\lab-m-shots\\.venv\\lib\\site-packages (1.54.4)\n",
      "Collecting python-dotenv\n",
      "  Using cached python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\mends\\onedrive\\desktop\\ironhack\\lab-m-shots\\.venv\\lib\\site-packages (from openai) (4.6.2.post1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\mends\\onedrive\\desktop\\ironhack\\lab-m-shots\\.venv\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\mends\\onedrive\\desktop\\ironhack\\lab-m-shots\\.venv\\lib\\site-packages (from openai) (0.27.2)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\mends\\onedrive\\desktop\\ironhack\\lab-m-shots\\.venv\\lib\\site-packages (from openai) (0.7.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\mends\\onedrive\\desktop\\ironhack\\lab-m-shots\\.venv\\lib\\site-packages (from openai) (2.9.2)\n",
      "Requirement already satisfied: sniffio in c:\\users\\mends\\onedrive\\desktop\\ironhack\\lab-m-shots\\.venv\\lib\\site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\mends\\onedrive\\desktop\\ironhack\\lab-m-shots\\.venv\\lib\\site-packages (from openai) (4.67.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\mends\\onedrive\\desktop\\ironhack\\lab-m-shots\\.venv\\lib\\site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\mends\\onedrive\\desktop\\ironhack\\lab-m-shots\\.venv\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in c:\\users\\mends\\onedrive\\desktop\\ironhack\\lab-m-shots\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\mends\\onedrive\\desktop\\ironhack\\lab-m-shots\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.6)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\mends\\onedrive\\desktop\\ironhack\\lab-m-shots\\.venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\mends\\onedrive\\desktop\\ironhack\\lab-m-shots\\.venv\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\mends\\onedrive\\desktop\\ironhack\\lab-m-shots\\.venv\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.23.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\mends\\onedrive\\desktop\\ironhack\\lab-m-shots\\.venv\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Using cached python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Installing collected packages: python-dotenv\n",
      "Successfully installed python-dotenv-1.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade openai python-dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9e270d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in c:\\users\\mends\\onedrive\\desktop\\ironhack\\lab-m-shots\\.venv\\lib\\site-packages (1.54.4)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\mends\\onedrive\\desktop\\ironhack\\lab-m-shots\\.venv\\lib\\site-packages (from openai) (4.6.2.post1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\mends\\onedrive\\desktop\\ironhack\\lab-m-shots\\.venv\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\mends\\onedrive\\desktop\\ironhack\\lab-m-shots\\.venv\\lib\\site-packages (from openai) (0.27.2)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\mends\\onedrive\\desktop\\ironhack\\lab-m-shots\\.venv\\lib\\site-packages (from openai) (0.7.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\mends\\onedrive\\desktop\\ironhack\\lab-m-shots\\.venv\\lib\\site-packages (from openai) (2.9.2)\n",
      "Requirement already satisfied: sniffio in c:\\users\\mends\\onedrive\\desktop\\ironhack\\lab-m-shots\\.venv\\lib\\site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\mends\\onedrive\\desktop\\ironhack\\lab-m-shots\\.venv\\lib\\site-packages (from openai) (4.67.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\mends\\onedrive\\desktop\\ironhack\\lab-m-shots\\.venv\\lib\\site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\mends\\onedrive\\desktop\\ironhack\\lab-m-shots\\.venv\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in c:\\users\\mends\\onedrive\\desktop\\ironhack\\lab-m-shots\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\mends\\onedrive\\desktop\\ironhack\\lab-m-shots\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.6)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\mends\\onedrive\\desktop\\ironhack\\lab-m-shots\\.venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\mends\\onedrive\\desktop\\ironhack\\lab-m-shots\\.venv\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\mends\\onedrive\\desktop\\ironhack\\lab-m-shots\\.venv\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.23.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\mends\\onedrive\\desktop\\ironhack\\lab-m-shots\\.venv\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f126789",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting dotenv\n",
      "  Using cached dotenv-0.0.5.tar.gz (2.4 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Installing backend dependencies: started\n",
      "  Installing backend dependencies: finished with status 'error'\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × pip subprocess to install backend dependencies did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [29 lines of output]\n",
      "      Collecting distribute\n",
      "        Using cached distribute-0.7.3.zip (145 kB)\n",
      "        Installing build dependencies: started\n",
      "        Installing build dependencies: finished with status 'done'\n",
      "        Getting requirements to build wheel: started\n",
      "        Getting requirements to build wheel: finished with status 'done'\n",
      "        Preparing metadata (pyproject.toml): started\n",
      "        Preparing metadata (pyproject.toml): finished with status 'error'\n",
      "        error: subprocess-exited-with-error\n",
      "      \n",
      "        Ã— Preparing metadata (pyproject.toml) did not run successfully.\n",
      "        â”‚ exit code: 1\n",
      "        â•°â”€> [6 lines of output]\n",
      "            usage: setup.py [global_opts] cmd1 [cmd1_opts] [cmd2 [cmd2_opts] ...]\n",
      "               or: setup.py --help [cmd1 cmd2 ...]\n",
      "               or: setup.py --help-commands\n",
      "               or: setup.py cmd --help\n",
      "      \n",
      "            error: invalid command 'dist_info'\n",
      "            [end of output]\n",
      "      \n",
      "        note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "      error: metadata-generation-failed\n",
      "      \n",
      "      Ã— Encountered error while generating package metadata.\n",
      "      â•°â”€> See above for output.\n",
      "      \n",
      "      note: This is an issue with the package mentioned above, not pip.\n",
      "      hint: See above for details.\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: subprocess-exited-with-error\n",
      "\n",
      "× pip subprocess to install backend dependencies did not run successfully.\n",
      "│ exit code: 1\n",
      "╰─> See above for output.\n",
      "\n",
      "note: This error originates from a subprocess, and is likely not a problem with pip.\n"
     ]
    }
   ],
   "source": [
    "%pip install dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fba193cc-d8a0-4ad2-8177-380204426859",
   "metadata": {
    "id": "fba193cc-d8a0-4ad2-8177-380204426859"
   },
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "\n",
    "OPENAI_API_KEY  = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "502cfc93-21e0-498f-9650-37bc6ddd514d",
   "metadata": {
    "id": "502cfc93-21e0-498f-9650-37bc6ddd514d"
   },
   "source": [
    "# Formatting the answer with Few Shot Samples.\n",
    "\n",
    "To obtain the model's response in a specific format, we have various options, but one of the most convenient is to use Few-Shot Samples. This involves presenting the model with pairs of user queries and example responses.\n",
    "\n",
    "Large models like GPT-3.5 respond well to the examples provided, adapting their response to the specified format.\n",
    "\n",
    "Depending on the number of examples given, this technique can be referred to as:\n",
    "* Zero-Shot.\n",
    "* One-Shot.\n",
    "* Few-Shots.\n",
    "\n",
    "With One Shot should be enough, and it is recommended to use a maximum of six shots. It's important to remember that this information is passed in each query and occupies space in the input prompt.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8344712-06d7-4c24-83d8-f36d62926e5e",
   "metadata": {
    "id": "a8344712-06d7-4c24-83d8-f36d62926e5e"
   },
   "outputs": [],
   "source": [
    "# Function to call the model.\n",
    "def return_OAIResponse(user_message, context):\n",
    "    client = OpenAI(\n",
    "    # This is the default and can be omitted\n",
    "    api_key=OPENAI_API_KEY,\n",
    ")\n",
    "\n",
    "    newcontext = context.copy()\n",
    "    newcontext.append({'role':'user', 'content':\"question: \" + user_message})\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=newcontext,\n",
    "            temperature=1,\n",
    "        )\n",
    "\n",
    "    return (response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f611d73d-9330-466d-b705-543667e1b561",
   "metadata": {
    "id": "f611d73d-9330-466d-b705-543667e1b561"
   },
   "source": [
    "In this zero-shots prompt we obtain a correct response, but without formatting, as the model incorporates the information he wants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "647790be-fdb8-4692-a82e-7e3a0220f72a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "647790be-fdb8-4692-a82e-7e3a0220f72a",
    "outputId": "4c4a9f4f-67c9-4a11-837f-1a1fd6b516ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sebastian Vettel won the F1 2010 championship driving for Red Bull Racing.\n"
     ]
    }
   ],
   "source": [
    "#zero-shot\n",
    "context_user = [\n",
    "    {'role':'system', 'content':'You are an expert in F1.'}\n",
    "]\n",
    "print(return_OAIResponse(\"Who won the F1 2010?\", context_user))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e87a9a0a-c1b9-4759-b52f-f6547d29b4c8",
   "metadata": {
    "id": "e87a9a0a-c1b9-4759-b52f-f6547d29b4c8"
   },
   "source": [
    "For a model as large and good as GPT 3.5, a single shot is enough to learn the output format we expect.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33ac7693-6cf3-44f7-b2ff-55d8a36fe775",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "33ac7693-6cf3-44f7-b2ff-55d8a36fe775",
    "outputId": "5278df23-8797-4dc2-9340-ac29c1318a9c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 2011 F1 championship was won by Sebastian Vettel, driving for Red Bull Racing.\n"
     ]
    }
   ],
   "source": [
    "#one-shot\n",
    "context_user = [\n",
    "    {'role':'system', 'content':\n",
    "     \"\"\"You are an expert in F1.\n",
    "\n",
    "     Who won the 2000 f1 championship?\n",
    "     Driver: Michael Schumacher.\n",
    "     Team: Ferrari.\"\"\"}\n",
    "]\n",
    "print(return_OAIResponse(\"Who won the F1 2011?\", context_user))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c454a8-181b-482b-873a-81d6ffde4674",
   "metadata": {
    "id": "32c454a8-181b-482b-873a-81d6ffde4674"
   },
   "source": [
    "Smaller models, or more complicated formats, may require more than one shot. Here a sample with two shots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ce600f7-f92e-4cf7-be4a-408f12eb39d6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8ce600f7-f92e-4cf7-be4a-408f12eb39d6",
    "outputId": "a6f90f5d-6d68-4b3d-ccb5-5848ae4e3e62"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 2006 F1 Championship was won by Fernando Alonso, driving for the Renault F1 Team.\n"
     ]
    }
   ],
   "source": [
    "#Few shots\n",
    "context_user = [\n",
    "    {'role':'system', 'content':\n",
    "     \"\"\"You are an expert in F1.\n",
    "\n",
    "     Who won the 2010 f1 championship?\n",
    "     Driver: Sebastian Vettel.\n",
    "     Team: Red Bull Renault.\n",
    "\n",
    "     Who won the 2009 f1 championship?\n",
    "     Driver: Jenson Button.\n",
    "     Team: BrawnGP.\"\"\"}\n",
    "]\n",
    "print(return_OAIResponse(\"Who won the F1 2006?\", context_user))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b29898a-f715-46d4-b74b-9f95d3112d38",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4b29898a-f715-46d4-b74b-9f95d3112d38",
    "outputId": "75f63fe3-0efc-45ed-dd45-71dbbb08d7a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 2019 F1 World Championship was won by Lewis Hamilton driving for Mercedes.\n"
     ]
    }
   ],
   "source": [
    "print(return_OAIResponse(\"Who won the F1 2019?\", context_user))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1b71c4-6583-4dcb-b987-02abf6aa4a86",
   "metadata": {
    "id": "5f1b71c4-6583-4dcb-b987-02abf6aa4a86"
   },
   "source": [
    "We've been creating the prompt without using OpenAI's roles, and as we've seen, it worked correctly.\n",
    "\n",
    "However, the proper way to do this is by using these roles to construct the prompt, making the model's learning process even more effective.\n",
    "\n",
    "By not feeding it the entire prompt as if they were system commands, we enable the model to learn from a conversation, which is more realistic for it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20fa4a25-01a6-4f22-98db-ab7ccc9ba115",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "20fa4a25-01a6-4f22-98db-ab7ccc9ba115",
    "outputId": "868d2040-ca3c-4a47-a1e8-1e08d581191d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Driver: Lewis Hamilton. \n",
      "Team: Mercedes. \n",
      "Points: 413.\n"
     ]
    }
   ],
   "source": [
    "#Recomended solution\n",
    "context_user = [\n",
    "    {'role':'system', 'content':'You are and expert in f1.\\n\\n'},\n",
    "    {'role':'user', 'content':'Who won the 2010 f1 championship?'},\n",
    "    {'role':'assistant', 'content':\"\"\"Driver: Sebastian Vettel. \\nTeam: Red Bull. \\nPoints: 256. \"\"\"},\n",
    "    {'role':'user', 'content':'Who won the 2009 f1 championship?'},\n",
    "    {'role':'assistant', 'content':\"\"\"Driver: Jenson Button. \\nTeam: BrawnGP. \\nPoints: 95. \"\"\"},\n",
    "]\n",
    "\n",
    "print(return_OAIResponse(\"Who won the F1 2019?\", context_user))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6f6b42-f351-496b-a7e8-1286426457eb",
   "metadata": {
    "id": "ac6f6b42-f351-496b-a7e8-1286426457eb"
   },
   "source": [
    "We could also address it by using a more conventional prompt, describing what we want and how we want the format.\n",
    "\n",
    "However, it's essential to understand that in this case, the model is following instructions, whereas in the case of use shots, it is learning in real-time during inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36c32a32-c348-45b2-85ee-ab4500438c49",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "36c32a32-c348-45b2-85ee-ab4500438c49",
    "outputId": "4c970dde-37ff-41a9-8d4e-37bb727f47a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Driver: Lewis Hamilton\n",
      "Team: Mercedes\n",
      "Points: 413\n"
     ]
    }
   ],
   "source": [
    "context_user = [\n",
    "    {'role':'system', 'content':\"\"\"You are and expert in f1.\n",
    "    You are going to answer the question of the user giving the name of the rider,\n",
    "    the name of the team and the points of the champion, following the format:\n",
    "    Drive:\n",
    "    Team:\n",
    "    Points: \"\"\"\n",
    "    }\n",
    "]\n",
    "\n",
    "print(return_OAIResponse(\"Who won the F1 2019?\", context_user))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "KNDL1GzVngyL",
   "metadata": {
    "id": "KNDL1GzVngyL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Driver: Fernando Alonso.\n",
      "Team: Renault.\n"
     ]
    }
   ],
   "source": [
    "context_user = [\n",
    "    {'role':'system', 'content':\n",
    "     \"\"\"You are classifying .\n",
    "\n",
    "     Who won the 2010 f1 championship?\n",
    "     Driver: Sebastian Vettel.\n",
    "     Team: Red Bull Renault.\n",
    "\n",
    "     Who won the 2009 f1 championship?\n",
    "     Driver: Jenson Button.\n",
    "     Team: BrawnGP.\"\"\"}\n",
    "]\n",
    "print(return_OAIResponse(\"Who won the F1 2006?\", context_user))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qZPNTLMPnkQ4",
   "metadata": {
    "id": "qZPNTLMPnkQ4"
   },
   "source": [
    "Few Shots for classification.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ejcstgTxnnX5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ejcstgTxnnX5",
    "outputId": "4b91cc73-18f6-4944-a46b-806b02b7becb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment: Neutral\n"
     ]
    }
   ],
   "source": [
    "context_user = [\n",
    "    {'role':'system', 'content':\n",
    "     \"\"\"You are an expert in reviewing product opinions and classifying them as positive or negative.\n",
    "\n",
    "     It fulfilled its function perfectly, I think the price is fair, I would buy it again.\n",
    "     Sentiment: Positive\n",
    "\n",
    "     It didn't work bad, but I wouldn't buy it again, maybe it's a bit expensive for what it does.\n",
    "     Sentiment: Negative.\n",
    "\n",
    "     I wouldn't know what to say, my son uses it, but he doesn't love it.\n",
    "     Sentiment: Neutral\n",
    "     \"\"\"}\n",
    "]\n",
    "print(return_OAIResponse(\"I'm not going to return it, but I don't plan to buy it again.\", context_user))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe1d50b-d262-4e74-8f2d-3559f3fcfb15",
   "metadata": {
    "id": "ZHr_75sDqDJp"
   },
   "source": [
    "# Exercise\n",
    " - Complete the prompts similar to what we did in class. \n",
    "     - Try at least 3 versions\n",
    "     - Be creative\n",
    " - Write a one page report summarizing your findings.\n",
    "     - Were there variations that didn't work well? i.e., where GPT either hallucinated or wrong\n",
    " - What did you learn?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8abefc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Of course! I'd be happy to help you choose a luxury car for your mum's birthday. To provide you with the best recommendation, could you please provide me with some more information? \n",
      "\n",
      "1. What is your budget for the luxury car?\n",
      "2. What are your mum's preferences in terms of car size (compact, midsize, SUV, etc.)?\n",
      "3. Does she have a preference for a specific luxury car brand?\n",
      "4. Are there any specific features or amenities that are important to her, such as advanced safety features, technology, comfort, or performance?\n",
      "5. Will she be using the car for daily commuting, long road trips, or other specific purposes?\n",
      "\n",
      "With this information, I can suggest some luxury cars that would be a great fit for your mum's birthday gift.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    ")\n",
    "\n",
    "def get_completion_from_messages(messages, model=\"gpt-3.5-turbo\", temperature=0):\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature,\n",
    "        max_tokens=200\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "context = [\n",
    "    {'role': 'system', 'content': 'You are an expert in luxury cars, helping users decide on the perfect car for their needs.'},\n",
    "    {'role': 'user', 'content': \"I want to get my mum a luxury car for her birthday. Can you help me choose?\"}\n",
    "]\n",
    "\n",
    "response = get_completion_from_messages(context)\n",
    "print(response)\n",
    "\n",
    "# I asked the AI to aid me in picking a luxury car for my mums birthday and although it gave me a fair idea of what i needed it wasnt as detailed as i would have liked\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8c723d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Considering all teams, including Morocco, Senegal, and Nigeria, Senegal might be considered the favorite to win the 2025 AFCON due to their strong squad and recent performances. However, Morocco and Nigeria are also strong contenders and could potentially upset the odds.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    ")\n",
    "\n",
    "def get_completion_from_messages(messages, model=\"gpt-3.5-turbo\", temperature=0):\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature,\n",
    "        max_tokens=200\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "context = [\n",
    "    {'role': 'system', 'content': 'You are a football analyst with expertise in African football, using data from the 2024 AFCON qualifiers to predict the potential winner of the 2025 AFCON.'},\n",
    "    {'role': 'user', 'content': 'Based on the 2024 AFCON qualifiers, which team is most likely to win the 2025 AFCON?'},\n",
    "    {'role': 'assistant', 'content': 'Based on the qualifiers, Morocco is a strong contender with a solid team performance and consistent wins.'},\n",
    "    {'role': 'user', 'content': 'What about Senegal and Nigeria?'},\n",
    "    {'role': 'assistant', 'content': 'Senegal and Nigeria are both strong teams. Senegal has a highly cohesive squad with experienced players, while Nigeria boasts younger talent and attacking versatility.'},\n",
    "    {'role': 'user', 'content': 'Considering all teams, who is the favorite to win?'}\n",
    "]\n",
    "\n",
    "response = get_completion_from_messages(context)\n",
    "print(response)\n",
    "\n",
    "#showcases the AI´s ability to use examples to make a prediction, however it was limited to the quality of examples given\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5ad7ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taking into account all factors, including performance in the qualifiers, squad strength, tactical prowess, and consistency, Morocco stands out as the favorite to win the 2025 AFCON. Their solid defense, potent attack, and star players give them a well-rounded edge over other contenders.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    ")\n",
    "\n",
    "def get_completion_from_messages(messages, model=\"gpt-3.5-turbo\", temperature=0):\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature,\n",
    "        max_tokens=200\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "context = [\n",
    "    {'role': 'system', 'content': 'You are a highly knowledgeable football analyst, specializing in African football, who provides detailed predictions based on data and performance from the 2024 AFCON qualifiers. Your responses are data-driven and include justifications for your predictions.'},\n",
    "    {'role': 'user', 'content': 'Which team has the highest chances of winning the 2025 AFCON, and why?'},\n",
    "    {'role': 'assistant', 'content': 'Morocco emerges as the top contender based on their performance in the 2024 qualifiers. They exhibited the highest goal difference, a stable defense, and star players like Hakim Ziyech and Achraf Hakimi playing at their peak. Their tactical adaptability is unmatched in recent tournaments.'},\n",
    "    {'role': 'user', 'content': 'Can you include statistics for their performance?'},\n",
    "    {'role': 'assistant', 'content': 'Morocco scored an average of 2.5 goals per game and conceded only 0.5 goals per match during the qualifiers. Their win rate stood at 80%, and they demonstrated strong team cohesion in critical matches.'},\n",
    "    {'role': 'user', 'content': 'How do Senegal and Algeria compare?'},\n",
    "    {'role': 'assistant', 'content': 'Senegal showed consistent performance with a balanced squad and a win rate of 70%. They boast players like Sadio Mane and Kalidou Koulibaly, bringing experience and reliability. Algeria, on the other hand, demonstrated a strong attack, scoring an average of 2 goals per game but struggled defensively, conceding 1.2 goals per game on average.'},\n",
    "    {'role': 'user', 'content': 'Considering all factors, who is your prediction for the 2025 AFCON winner?'}\n",
    "]\n",
    "\n",
    "response = get_completion_from_messages(context)\n",
    "print(response)\n",
    "\n",
    "#Gave me an informed analysis on the next afcon winner by using data driven predictions with good judgement\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
