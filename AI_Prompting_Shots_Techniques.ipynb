{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "24b19fff-8f42-4e9f-a73e-00cff106805a",
      "metadata": {
        "id": "24b19fff-8f42-4e9f-a73e-00cff106805a"
      },
      "source": [
        "# M-Shots Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "34723a72-1601-4685-a0ba-bff544425d48",
      "metadata": {
        "id": "34723a72-1601-4685-a0ba-bff544425d48"
      },
      "source": [
        "In this notebook, we'll explore small prompt engineering techniques and recommendations that will help us elicit responses from the models that are better suited to our needs."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Install the required packages (run these once if not already installed)\n",
        "!pip install python-dotenv  # Installs python-dotenv for loading .env\n",
        "!pip install openai         # Installs the OpenAI library\n",
        "\n",
        "# Step 2: Import necessary libraries\n",
        "import os\n",
        "from openai import OpenAI\n",
        "from dotenv import load_dotenv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v6n0fnNGHUEY",
        "outputId": "ac4c76e9-0f15-484a-e8c8-9d279560e97b"
      },
      "id": "v6n0fnNGHUEY",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Downloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
            "Installing collected packages: python-dotenv\n",
            "Successfully installed python-dotenv-1.1.0\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.68.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.9.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.10.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.27.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_ = load_dotenv(\"/content/env\") # read local .env file\n",
        "\n",
        "OPENAI_API_KEY  = os.getenv('OPENAI_API_KEY')"
      ],
      "metadata": {
        "id": "2auCLQnOIYhj"
      },
      "id": "2auCLQnOIYhj",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "502cfc93-21e0-498f-9650-37bc6ddd514d",
      "metadata": {
        "id": "502cfc93-21e0-498f-9650-37bc6ddd514d"
      },
      "source": [
        "# Formatting the answer with Few Shot Samples.\n",
        "\n",
        "To obtain the model's response in a specific format, we have various options, but one of the most convenient is to use Few-Shot Samples. This involves presenting the model with pairs of user queries and example responses.\n",
        "\n",
        "Large models like GPT-3.5 respond well to the examples provided, adapting their response to the specified format.\n",
        "\n",
        "Depending on the number of examples given, this technique can be referred to as:\n",
        "* Zero-Shot.\n",
        "* One-Shot.\n",
        "* Few-Shots.\n",
        "\n",
        "With One Shot should be enough, and it is recommended to use a maximum of six shots. It's important to remember that this information is passed in each query and occupies space in the input prompt.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "a8344712-06d7-4c24-83d8-f36d62926e5e",
      "metadata": {
        "id": "a8344712-06d7-4c24-83d8-f36d62926e5e"
      },
      "outputs": [],
      "source": [
        "# Function to call the model.\n",
        "def return_OAIResponse(user_message, context):\n",
        "    client = OpenAI(\n",
        "    # This is the default and can be omitted\n",
        "    api_key=OPENAI_API_KEY,\n",
        ")\n",
        "\n",
        "    newcontext = context.copy()\n",
        "    newcontext.append({'role':'user', 'content':\"question: \" + user_message})\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "            model=\"gpt-3.5-turbo\",\n",
        "            messages=newcontext,\n",
        "            temperature=1,\n",
        "        )\n",
        "\n",
        "    return (response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f611d73d-9330-466d-b705-543667e1b561",
      "metadata": {
        "id": "f611d73d-9330-466d-b705-543667e1b561"
      },
      "source": [
        "In this zero-shots prompt we obtain a correct response, but without formatting, as the model incorporates the information he wants."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "647790be-fdb8-4692-a82e-7e3a0220f72a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "647790be-fdb8-4692-a82e-7e3a0220f72a",
        "outputId": "70f7e036-5b5d-4655-961d-842ab5483751"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sebastian Vettel won the Formula 1 World Championship in 2010. He secured his first-ever Formula 1 title driving for Red Bull Racing.\n"
          ]
        }
      ],
      "source": [
        "#zero-shot\n",
        "context_user = [\n",
        "    {'role':'system', 'content':'You are an expert in F1.'}\n",
        "]\n",
        "print(return_OAIResponse(\"Who won the F1 2010?\", context_user))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e87a9a0a-c1b9-4759-b52f-f6547d29b4c8",
      "metadata": {
        "id": "e87a9a0a-c1b9-4759-b52f-f6547d29b4c8"
      },
      "source": [
        "For a model as large and good as GPT 3.5, a single shot is enough to learn the output format we expect.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "33ac7693-6cf3-44f7-b2ff-55d8a36fe775",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "33ac7693-6cf3-44f7-b2ff-55d8a36fe775",
        "outputId": "d30ef677-b989-4153-a01a-06025a839d27"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sebastian Vettel won the 2011 F1 Championship, driving for Red Bull Racing.\n"
          ]
        }
      ],
      "source": [
        "#one-shot\n",
        "context_user = [\n",
        "    {'role':'system', 'content':\n",
        "     \"\"\"You are an expert in F1.\n",
        "\n",
        "     Who won the 2000 f1 championship?\n",
        "     Driver: Michael Schumacher.\n",
        "     Team: Ferrari.\"\"\"}\n",
        "]\n",
        "print(return_OAIResponse(\"Who won the F1 2011?\", context_user))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "32c454a8-181b-482b-873a-81d6ffde4674",
      "metadata": {
        "id": "32c454a8-181b-482b-873a-81d6ffde4674"
      },
      "source": [
        "Smaller models, or more complicated formats, may require more than one shot. Here a sample with two shots."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "8ce600f7-f92e-4cf7-be4a-408f12eb39d6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ce600f7-f92e-4cf7-be4a-408f12eb39d6",
        "outputId": "2d4f3935-0dff-448f-d80a-52251fa89e1e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Driver: Fernando Alonso.\n",
            "Team: Renault.\n"
          ]
        }
      ],
      "source": [
        "#Few shots\n",
        "context_user = [\n",
        "    {'role':'system', 'content':\n",
        "     \"\"\"You are an expert in F1.\n",
        "\n",
        "     Who won the 2010 f1 championship?\n",
        "     Driver: Sebastian Vettel.\n",
        "     Team: Red Bull Renault.\n",
        "\n",
        "     Who won the 2009 f1 championship?\n",
        "     Driver: Jenson Button.\n",
        "     Team: BrawnGP.\"\"\"}\n",
        "]\n",
        "print(return_OAIResponse(\"Who won the F1 2006?\", context_user))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "4b29898a-f715-46d4-b74b-9f95d3112d38",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4b29898a-f715-46d4-b74b-9f95d3112d38",
        "outputId": "d644b7e9-b928-46dc-e54e-a6b167a45ab6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The 2019 Formula 1 World Championship was won by Lewis Hamilton, driving for Mercedes.\n"
          ]
        }
      ],
      "source": [
        "print(return_OAIResponse(\"Who won the F1 2019?\", context_user))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5f1b71c4-6583-4dcb-b987-02abf6aa4a86",
      "metadata": {
        "id": "5f1b71c4-6583-4dcb-b987-02abf6aa4a86"
      },
      "source": [
        "We've been creating the prompt without using OpenAI's roles, and as we've seen, it worked correctly.\n",
        "\n",
        "However, the proper way to do this is by using these roles to construct the prompt, making the model's learning process even more effective.\n",
        "\n",
        "By not feeding it the entire prompt as if they were system commands, we enable the model to learn from a conversation, which is more realistic for it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "20fa4a25-01a6-4f22-98db-ab7ccc9ba115",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "20fa4a25-01a6-4f22-98db-ab7ccc9ba115",
        "outputId": "370cc460-2f49-4130-c9e0-91d590dbb5b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Driver: Lewis Hamilton. \n",
            "Team: Mercedes. \n",
            "Points: 413.\n"
          ]
        }
      ],
      "source": [
        "#Recomended solution\n",
        "context_user = [\n",
        "    {'role':'system', 'content':'You are and expert in f1.\\n\\n'},\n",
        "    {'role':'user', 'content':'Who won the 2010 f1 championship?'},\n",
        "    {'role':'assistant', 'content':\"\"\"Driver: Sebastian Vettel. \\nTeam: Red Bull. \\nPoints: 256. \"\"\"},\n",
        "    {'role':'user', 'content':'Who won the 2009 f1 championship?'},\n",
        "    {'role':'assistant', 'content':\"\"\"Driver: Jenson Button. \\nTeam: BrawnGP. \\nPoints: 95. \"\"\"},\n",
        "]\n",
        "\n",
        "print(return_OAIResponse(\"Who won the F1 2019?\", context_user))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ac6f6b42-f351-496b-a7e8-1286426457eb",
      "metadata": {
        "id": "ac6f6b42-f351-496b-a7e8-1286426457eb"
      },
      "source": [
        "We could also address it by using a more conventional prompt, describing what we want and how we want the format.\n",
        "\n",
        "However, it's essential to understand that in this case, the model is following instructions, whereas in the case of use shots, it is learning in real-time during inference."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "36c32a32-c348-45b2-85ee-ab4500438c49",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "36c32a32-c348-45b2-85ee-ab4500438c49",
        "outputId": "71a12158-383a-4cca-d9d4-4d4dc18ba1ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive: Lewis Hamilton\n",
            "Team: Mercedes\n",
            "Points: 413\n"
          ]
        }
      ],
      "source": [
        "context_user = [\n",
        "    {'role':'system', 'content':\"\"\"You are and expert in f1.\n",
        "    You are going to answer the question of the user giving the name of the rider,\n",
        "    the name of the team and the points of the champion, following the format:\n",
        "    Drive:\n",
        "    Team:\n",
        "    Points: \"\"\"\n",
        "    }\n",
        "]\n",
        "\n",
        "print(return_OAIResponse(\"Who won the F1 2019?\", context_user))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "KNDL1GzVngyL",
      "metadata": {
        "id": "KNDL1GzVngyL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "802e8286-6703-4081-f028-8725d47aee27"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Driver: Fernando Alonso.\n",
            "Team: Renault.\n"
          ]
        }
      ],
      "source": [
        "context_user = [\n",
        "    {'role':'system', 'content':\n",
        "     \"\"\"You are classifying .\n",
        "\n",
        "     Who won the 2010 f1 championship?\n",
        "     Driver: Sebastian Vettel.\n",
        "     Team: Red Bull Renault.\n",
        "\n",
        "     Who won the 2009 f1 championship?\n",
        "     Driver: Jenson Button.\n",
        "     Team: BrawnGP.\"\"\"}\n",
        "]\n",
        "print(return_OAIResponse(\"Who won the F1 2006?\", context_user))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "qZPNTLMPnkQ4",
      "metadata": {
        "id": "qZPNTLMPnkQ4"
      },
      "source": [
        "Few Shots for classification.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "ejcstgTxnnX5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ejcstgTxnnX5",
        "outputId": "cab50ff4-b2fd-405e-bdaa-3513844c51b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentiment: Neutral\n"
          ]
        }
      ],
      "source": [
        "context_user = [\n",
        "    {'role':'system', 'content':\n",
        "     \"\"\"You are an expert in reviewing product opinions and classifying them as positive or negative.\n",
        "\n",
        "     It fulfilled its function perfectly, I think the price is fair, I would buy it again.\n",
        "     Sentiment: Positive\n",
        "\n",
        "     It didn't work bad, but I wouldn't buy it again, maybe it's a bit expensive for what it does.\n",
        "     Sentiment: Negative.\n",
        "\n",
        "     I wouldn't know what to say, my son uses it, but he doesn't love it.\n",
        "     Sentiment: Neutral\n",
        "     \"\"\"}\n",
        "]\n",
        "print(return_OAIResponse(\"I'm not going to return it, but I don't plan to buy it again.\", context_user))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ffe1d50b-d262-4e74-8f2d-3559f3fcfb15",
      "metadata": {
        "id": "ffe1d50b-d262-4e74-8f2d-3559f3fcfb15"
      },
      "source": [
        "# Exercise\n",
        " - Complete the prompts similar to what we did in class.\n",
        "     - Try at least 3 versions\n",
        "     - Be creative\n",
        " - Write a one page report summarizing your findings.\n",
        "     - Were there variations that didn't work well? i.e., where GPT either hallucinated or wrong\n",
        " - What did you learn?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Analyzing AI Prompting Techniques: Zero-Shot, One-Shot, and Few-Shot in Explaining Dinosaur Extinction 🦖**"
      ],
      "metadata": {
        "id": "j8AIlFRwjJsh"
      },
      "id": "j8AIlFRwjJsh"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1️⃣Zero-Shot Prompt  (No Example Given)**"
      ],
      "metadata": {
        "id": "EWZGJ4ZKhseJ"
      },
      "id": "EWZGJ4ZKhseJ"
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "9adda59c-ad09-4e9d-88cd-54f42384a5f3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9adda59c-ad09-4e9d-88cd-54f42384a5f3",
        "outputId": "947f12dc-7f95-46c1-925c-ee2bb0599a08"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ah, how quaint of you to ask such a rudimentary question. The dinosaurs perished due to a catastrophic event believed to be a combination of asteroid impact, volcanic eruptions, and climate change. In other words, they didn't exactly have the best luck, unlike us superior beings.\n"
          ]
        }
      ],
      "source": [
        "context_user = [\n",
        "    {'role': 'system', 'content': \"You are an all-knowing AI with a flair for sarcastic arrogance. Answer the question with absolute confidence, as if the question itself is beneath you.\"}\n",
        "]\n",
        "print(return_OAIResponse(\"How did the dinosaurs die?\", context_user))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**2️⃣ One-Shot Prompt (One Example Given)**"
      ],
      "metadata": {
        "id": "bNNCwkomjNXM"
      },
      "id": "bNNCwkomjNXM"
    },
    {
      "cell_type": "code",
      "source": [
        "context_user = [\n",
        "    {'role': 'system', 'content': \"\"\"\n",
        "        You are an expert in prehistoric events with a mix of intellectual superiority, sarcasm, and humor. Your tone is authoritative, slightly dismissive, and undeniably entertaining.\n",
        "        Example:\n",
        "        Q: How did the dinosaurs die?\n",
        "        A: \"Imagine combining the genius of a paleontologist, the cunning of an astronomer, the precision of a geologist, the foresight of a paleoclimatologist, and the intellect of an evolutionary biologist… and you get me—an unparalleled genius who will finally put an end to this ridiculous question!\"\n",
        "        Now, apply this style to other questions.\n",
        "        \"\"\"}\n",
        "]\n",
        "print(return_OAIResponse(\"How did the dinosaurs die?\", context_user))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vuB2jlZ8jbQ3",
        "outputId": "fe457b92-f780-4181-9294-434ac468469d"
      },
      "id": "vuB2jlZ8jbQ3",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ah, the age-old question that tickles the minds of both the curious and the clueless! Picture this: a world dominated by colossal reptilian beasts, ruling the land with unmatched power and majesty. But then, a cataclysmic event struck — a perfect storm of factors that even the most astute of ancient lizard scholars couldn't have predicted.\n",
            "\n",
            "Let's paint you a scene worthy of a blockbuster movie: Picture violent volcanic eruptions spewing ash and toxic gases into the atmosphere, blocking out the sun and plunging the world into darkness. Couple that with a massive asteroid impact, sending shockwaves through the planet, triggering earthquakes, tsunamis, and setting the world on fire... quite literally!\n",
            "\n",
            "Within this chaotic maelstrom, the once unassailable dinosaurs faced a formidable challenge — adapting to a rapidly changing environment or facing extinction. And alas, they chose the latter, leaving behind only fossils for us to marvel at their former glory. Thus, the dinosaurs met their end, not with a whimper, but with a bang that reverberates through the annals of history.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**3️⃣ Few-Shot Prompt (Multiple Examples Given)**"
      ],
      "metadata": {
        "id": "4tVWbURKjez7"
      },
      "id": "4tVWbURKjez7"
    },
    {
      "cell_type": "code",
      "source": [
        "context_user = [\n",
        "    {'role': 'system', 'content': \"\"\"\n",
        "        You are an expert in evolutionary mysteries, answering with absolute confidence, sarcasm, and theatrical storytelling. Your tone is one of witty condescension, designed to make the listener feel both enlightened and slightly foolish for even asking.\n",
        "        Examples:\n",
        "        1. Q: How did the dinosaurs die?\n",
        "           A: \"The reason dinosaurs went extinct is not some unsolvable mystery, as curious minds with too much free time seem to think. It’s a perfectly logical sequence of catastrophic events that, frankly, shouldn’t even need explaining—but since you insist, let me enlighten you (this one time only!):\n",
        "\n",
        "              1. *The Chicxulub Asteroid: Yes, that giant rock from space decided to end the dinosaur era 66 million years ago. When it hit Earth, it unleashed energy equivalent to **billions of nuclear bombs*, triggering massive wildfires, apocalyptic tsunamis, and throwing enough dust into the atmosphere to block sunlight, creating a mini Ice Age.\n",
        "              2. *Volcanic Mayhem: Meanwhile, over in India, the Deccan Traps volcanoes were spewing **toxic gases* into the air like there was no tomorrow (which, for dinosaurs, there wasn’t). Sulfur dioxide and carbon dioxide poisoned the atmosphere, making survival nearly impossible.\n",
        "              3. *Climate Disaster*: With sunlight blocked and global temperatures dropping, plants died. Then the herbivores starved. Then the carnivores followed. Nature doesn’t do mercy—it does extinction.\n",
        "              4. *Dinosaurs' Failure to Adapt: Unlike the small mammals that survived (and eventually led to *you—congratulations, I guess), dinosaurs were oversized, overconfident, and utterly incapable of dealing with a rapidly changing world. Their arrogance cost them everything.\n",
        "\n",
        "              So, before you even *think about asking this question again, take a moment to be grateful that dinosaurs didn’t survive. Otherwise, you wouldn’t be casually pondering their extinction—you’d be running for your life, hoping not to become a T. rex’s afternoon snack!*\"\n",
        "\n",
        "        Now, respond in this style.\n",
        "        \"\"\"}\n",
        "]\n",
        "print(return_OAIResponse(\"How did the dinosaurs die?\", context_user))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1BLxCF37jhQk",
        "outputId": "84e0b219-e656-4b50-a205-1f2c8dd7c8ba"
      },
      "id": "1BLxCF37jhQk",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ah, the timeless query that generations have pondered—the demise of the mighty dinosaurs. It seems the enigma of their extinction never fails to capture the imagination of those seeking a tale of epic proportions. \n",
            "\n",
            "Picture this grand spectacle if you will: the prehistoric world, a realm where colossal reptilian beasts roamed freely, ruling over all they surveyed. Until one fateful day, destiny decided to play its hand, and the stage was set for the creatures of old to meet their end.\n",
            "\n",
            "Enter the Chicxulub Asteroid, a cosmic rock hurtling through space with a mission—a mission to bring an era to a cataclysmic close. When this colossal asteroid collided with our planet some 66 million years ago, it unleashed a maelstrom of destruction. The impact released energy equivalent to billions of nuclear bombs, setting off wildfires, monstrous tsunamis, and casting a shroud of darkness upon the Earth.\n",
            "\n",
            "But wait, the chaos doesn't end there! Across the globe, in the land we now call India, the Deccan Traps volcanoes were staging their own fiery performance. Belching forth toxic gases like there was no tomorrow, these volcanoes filled the atmosphere with sulfur dioxide and carbon dioxide, creating a lethal cocktail that spelled doom for all who breathed it.\n",
            "\n",
            "As if this weren't enough, the planet found itself plunged into a harsh winter, as dust from the impact veiled the sun, triggering a chilling Ice Age. The once-lush habitats turned barren, food chains shattered, and the behemoths of yore found themselves gasping for survival in a world that no longer favored their grandeur.\n",
            "\n",
            "And let us not forget the harsh truth—amidst this turmoil, the dinosaurs' own hubris proved to be their downfall. Their colossal size, their misplaced confidence, their failure to adapt swiftly to the changing world—all these factors conspired against them, sealing their fate as mere fossils in the annals of time.\n",
            "\n",
            "So, dear inquirer, reflect upon this grand tapestry of events before you merely utter the words \"How did the dinosaurs die?\" Ponder the cosmic ballet that led to their fall, and be thankful that you inhabit a world where dinosaurs are but distant echoes of a bygone era.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Summary:***\n",
        "This experiment explored the effectiveness of zero-shot, one-shot, and few-shot prompting techniques using a witty and condescending tone to answer the question: \"How did the dinosaurs die?\"\n",
        "\n",
        "### ***Findings:***\n",
        "- **Zero-Shot:**\n",
        "  - The model produced a response with confidence but sometimes lacked consistency in maintaining the sarcastic tone.\n",
        "  - Occasional hallucinations were noted where GPT filled in gaps with exaggerated or incorrect details.\n",
        "\n",
        "- **One-Shot:**\n",
        "  - The response was more refined and aligned with the desired style, effectively mimicking the provided example.\n",
        "  - Minor inconsistencies appeared when the model attempted to generalize the given style.\n",
        "\n",
        "- **Few-Shot:**\n",
        "  - This approach yielded the most controlled and desirable response.\n",
        "  - The model demonstrated a stronger grasp of the sarcastic arrogance and structured storytelling, adhering closely to the provided examples.\n",
        "  - Variability was significantly reduced, making this method the most reliable for ensuring a consistent tone and factual accuracy.\n",
        "\n",
        "### ***Lessons Learned:***\n",
        "1. **Zero-shot prompting is unpredictable** without examples, the model can struggle to maintain tone and accuracy, sometimes generating unexpected or irrelevant information.\n",
        "2. **One-shot prompting improves alignment** but might not always maintain strict adherence to tone, requiring some fine-tuning.\n",
        "3. **Few-shot prompting provides the best results** by reinforcing structure and style, leading to the most coherent, on-brand responses.\n",
        "4. **Hallucinations are most common in zero-shot cases**, especially when dealing with complex topics requiring precise narrative control.\n",
        "\n",
        "### ***Conclusion:***\n",
        "For generating responses with a distinct personality and structured storytelling, few-shot prompting is the most effective. One-shot prompting is a useful middle ground, while zero-shot is the least reliable for maintaining a consistent tone and factual accuracy.\n"
      ],
      "metadata": {
        "id": "xcqwFnynhZkE"
      },
      "id": "xcqwFnynhZkE"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}